{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Naive Bayes</center>\n",
    "## <div align='right'>Made by:</div>\n",
    "**<div align='right'>Ihor Markevych</div>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a Naive Bayes classifier to apply it to the task of classifying handwritten digits. Files `mnist_train` and `mnist_test` contain training and test digits, together with their ground truth labels (first column). Each row in these files corresponds to a different digit.  \n",
    "  \n",
    "Each image is 28x28, hence there are 784 pixel in every image. Columns 2-785 in the data files correspond to the pixel intensity, a value between 0 to 255. Column 1 corresponds to the correct label for each digit.  \n",
    "  \n",
    "The pixel intensities will be converted to a single binary indicator feature ($F_i$) for each pixel. Specifically, if the intensity is smaller than 255/2 it will be mapped to a zero, otherwise to a one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./mnist_train.csv', header=None)\n",
    "test = pd.read_csv('./mnist_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = train.iloc[:, 0]\n",
    "trainX = train.iloc[:, 1:]\n",
    "\n",
    "testY = test.iloc[:, 0]\n",
    "testX = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.applymap(lambda x: int(x > 255 / 2))\n",
    "testX = testX.applymap(lambda x: int(x > 255 / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinNaiveBayes:\n",
    "    \n",
    "    def __init__(self, smoothingCoef = 1):\n",
    "        self.smoothingCoef = smoothingCoef\n",
    "    \n",
    "    def fit(self, trainX, trainY):\n",
    "        self.prior = trainY.value_counts(sort=False)\n",
    "        self.likelihood = np.array([np.sum(trainX.loc[trainY == i, :], axis=0) \n",
    "                                    for i in np.unique(trainY)])\n",
    "        self.likelihood = (self.likelihood + self.smoothingCoef ) \\\n",
    "                            / (np.array(self.prior)[:, None] + 2 * self.smoothingCoef)\n",
    "        \n",
    "        self.prior /= len(trainY)\n",
    "        \n",
    "    def logProb(self, testXRow):\n",
    "        return np.sum(\n",
    "                np.log(\n",
    "                    np.abs(\n",
    "                        np.abs(np.array(testXRow) - 1) - self.likelihood\n",
    "                    )\n",
    "                ), axis=1) + np.log(self.prior)\n",
    "        \n",
    "    def predict(self, testX):\n",
    "        if isinstance(testX, pd.Series):\n",
    "            testX = pd.DataFrame(testX).T\n",
    "        \n",
    "        return [np.argmax(self.logProb(testXRow)) \n",
    "                for _, testXRow in testX.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = BinNaiveBayes()\n",
    "NB.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the priors $P(class)$ based on the frequencies of different classes in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.099\n",
       "1    0.112\n",
       "2    0.099\n",
       "3    0.102\n",
       "4    0.097\n",
       "5    0.090\n",
       "6    0.099\n",
       "7    0.104\n",
       "8    0.098\n",
       "9    0.099\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(NB.prior, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the likelihoods $P(F_i|class)$ for every pixel location $i$ and for every digit class from $0$ to $9$.  \n",
    "  \n",
    "  \n",
    "The likelihood estimate is  \n",
    "$P(F_i = f|class)$ = (Number of times pixel $i$ has value $f$ in training examples from this class) / (Total number of training examples from this class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihoods should be smoothed to ensure that there are no zero counts. Laplace smoothing is a very simple method that increases the observation count of every value $f$ by some constant $k$. This corresponds to adding $k$ to the numerator above, and $k*V$ to the denominator (where $V$ is the number of possible values the feature can take on). The higher the value of $k$, the stronger the smoothing. Experiment with different integer values of $k$ from $1$ to $5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=1:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{682} = 0|class = 5)=$ 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{772} = 1|class = 9)=$ 0.001"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For k=2:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{682} = 0|class = 5)=$ 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{772} = 1|class = 9)=$ 0.001"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For k=3:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{682} = 0|class = 5)=$ 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{772} = 1|class = 9)=$ 0.001"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For k=4:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{682} = 0|class = 5)=$ 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{772} = 1|class = 9)=$ 0.002"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For k=5:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{682} = 0|class = 5)=$ 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(F_{772} = 1|class = 9)=$ 0.002"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range (1, 6):\n",
    "    NB = BinNaiveBayes(k)\n",
    "    NB.fit(trainX, trainY)\n",
    "    print(f'For k={str(k)}:')\n",
    "    display(Markdown('$P(F_{682} = 0|class = 5)=$ ' + str(round(1 - NB.likelihood[5, 681], 3))))\n",
    "    display(Markdown('$P(F_{772} = 1|class = 9)=$ ' + str(round(NB.likelihood[9, 771], 3))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum a posteriori (MAP) classification of test digits according to the learned Naive Bayes modeles.  \n",
    "  \n",
    "Suppose a test image has feature values $f_1, f_2, ... , f_{784}$. According to this model, the posterior probability (up to scale) of each class given the digit is given by:  \n",
    "  \n",
    "$P(class)P(f_1|class)(f_2|class)...P(f_{784}|class)$\n",
    "  \n",
    "Note that in order to avoid underflow, we need to work with the log of the above quantity:\n",
    "  \n",
    "$log P(class) + log P(f_1|class) + log P(f_2|class) + ... + log P(f_{784}|class)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For first test image, k = 1:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$log P(class = 5|f_1, f_2, ..., f_784)=$ -206.09087174321996"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$log P(class = 7|f_1, f_2, ..., f_784)=$ -114.6256618113011"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NB = BinNaiveBayes()\n",
    "NB.fit(trainX, trainY)\n",
    "print('For first test image, k = 1:')\n",
    "display(Markdown('$log P(class = 5|f_1, f_2, ..., f_784)=$ ' + str(NB.logProb(testX.iloc[0])[5])))\n",
    "display(Markdown('$log P(class = 7|f_1, f_2, ..., f_784)=$ ' + str(NB.logProb(testX.iloc[0])[7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For first test image, k = 5:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$log P(class = 5|f_1, f_2, ..., f_784)=$ -205.91085479090967"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$log P(class = 7|f_1, f_2, ..., f_784)=$ -115.0183296837904"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NB = BinNaiveBayes(5)\n",
    "NB.fit(trainX, trainY)\n",
    "print('For first test image, k = 5:')\n",
    "display(Markdown('$log P(class = 5|f_1, f_2, ..., f_784)=$ ' + str(NB.logProb(testX.iloc[0])[5])))\n",
    "display(Markdown('$log P(class = 7|f_1, f_2, ..., f_784)=$ ' + str(NB.logProb(testX.iloc[0])[7])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance in terms of the classification rate (percentage of all test images correctly classified) for each value of $k$ from $1$ to $5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dergel\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:61: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for k=1: 84.27%.\n",
      "Accuracy score for k=2: 84.25%.\n",
      "Accuracy score for k=3: 84.19%.\n",
      "Accuracy score for k=4: 84.17%.\n",
      "Accuracy score for k=5: 84.11999999999999%.\n"
     ]
    }
   ],
   "source": [
    "for k in range (1, 6):\n",
    "    NB = BinNaiveBayes(k)\n",
    "    NB.fit(trainX, trainY)\n",
    "    pred = NB.predict(testX)\n",
    "    print(f'Accuracy score for k={k}: {sklearn.metrics.accuracy_score(testY, pred) * 100}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix for $k=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 882,    0,    3,    4,    1,   51,   21,    1,   17,    0],\n",
       "       [   0, 1086,    6,    5,    0,    9,    4,    0,   25,    0],\n",
       "       [  17,   14,  840,   32,   21,    5,   28,   16,   57,    2],\n",
       "       [   4,   17,   36,  839,    1,   30,    7,   13,   44,   19],\n",
       "       [   2,    7,    4,    0,  799,    2,   16,    2,   12,  138],\n",
       "       [  16,   11,    5,  106,   24,  655,   18,    8,   24,   25],\n",
       "       [  17,   14,   15,    1,   14,   37,  853,    0,    7,    0],\n",
       "       [   2,   33,   17,    3,   17,    0,    0,  864,   25,   67],\n",
       "       [  10,   28,   12,   68,   16,   27,   10,    6,  762,   35],\n",
       "       [  12,   13,    6,    8,   64,    9,    0,   29,   21,  847]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = BinNaiveBayes()\n",
    "NB.fit(trainX, trainY)\n",
    "pred = NB.predict(testX)\n",
    "sklearn.metrics.confusion_matrix(testY, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
